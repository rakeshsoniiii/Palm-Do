import cv2
import numpy as np
import mediapipe as mp
import os
import pickle
import sqlite3
from io import BytesIO
from PIL import Image
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV, cross_val_score
from collections import defaultdict
import pyttsx3
import threading
import time

class PalmDatabase:
    def __init__(self, db_file="palm_biometric.db"):
        self.conn = sqlite3.connect(db_file)
        self.create_tables()
        
    def create_tables(self):
        cursor = self.conn.cursor()
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS users (
            user_id TEXT PRIMARY KEY,
            name TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )""")
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS palm_scans (
            scan_id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            image BLOB,
            features BLOB,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY(user_id) REFERENCES users(user_id)
        )""")
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS models (
            model_id INTEGER PRIMARY KEY AUTOINCREMENT,
            model_data BLOB,
            accuracy REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )""")
        
        self.conn.commit()
    
    def add_user(self, user_id, name=None):
        try:
            cursor = self.conn.cursor()
            cursor.execute("INSERT INTO users (user_id, name) VALUES (?, ?)", 
                         (user_id, name))
            self.conn.commit()
            return True
        except sqlite3.IntegrityError:
            return False
    
    def add_scan(self, user_id, image, features):
        try:
            # Convert image to bytes
            img_byte_arr = BytesIO()
            Image.fromarray(image).save(img_byte_arr, format='PNG')
            img_bytes = img_byte_arr.getvalue()
            
            # Serialize features
            feat_bytes = pickle.dumps(features)
            
            cursor = self.conn.cursor()
            cursor.execute("""
                INSERT INTO palm_scans (user_id, image, features)
                VALUES (?, ?, ?)
            """, (user_id, img_bytes, feat_bytes))
            self.conn.commit()
            return cursor.lastrowid
        except Exception as e:
            print("Error saving scan:", e)
            return None
    
    def get_user_scans(self, user_id):
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT image, features FROM palm_scans 
            WHERE user_id = ?
            ORDER BY timestamp
        """, (user_id,))
        return cursor.fetchall()
    
    def get_all_features(self):
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT user_id, features FROM palm_scans
        """)
        return cursor.fetchall()
    
    def save_model(self, model, accuracy):
        try:
            model_bytes = pickle.dumps(model)
            cursor = self.conn.cursor()
            cursor.execute("""
                INSERT INTO models (model_data, accuracy)
                VALUES (?, ?)
            """, (model_bytes, accuracy))
            self.conn.commit()
            return cursor.lastrowid
        except Exception as e:
            print("Error saving model:", e)
            return None
    
    def load_latest_model(self):
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT model_data FROM models
            ORDER BY created_at DESC
            LIMIT 1
        """)
        result = cursor.fetchone()
        if result:
            return pickle.loads(result[0])
        return None
    
    def get_user_list(self):
        cursor = self.conn.cursor()
        cursor.execute("SELECT user_id, name FROM users")
        return cursor.fetchall()
    
    def close(self):
        self.conn.close()

class PalmBiometricSystem:
    def __init__(self):
        # Initialize database
        self.db = PalmDatabase()
        
        # MediaPipe Hands
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.6
        )
        self.mp_drawing = mp.solutions.drawing_utils

        # Model
        self.model = self.db.load_latest_model()

        # Flags
        self.capture_running = False
        self.recognize_running = False

        # Text-to-speech engine
        self.tts_engine = pyttsx3.init()
        self.tts_engine.setProperty('rate', 150)
    
    def speak(self, text):
        """Voice assistant via pyttsx3 (non-blocking)"""
        def _s():
            try:
                self.tts_engine.say(text)
                self.tts_engine.runAndWait()
            except Exception as e:
                print("TTS error:", e)
        threading.Thread(target=_s, daemon=True).start()

    def _landmark_to_np(self, landmarks):
        """Convert MediaPipe landmarks into Nx3 numpy array"""
        arr = np.zeros((21, 3), dtype=np.float32)
        for i, lm in enumerate(landmarks.landmark):
            arr[i, 0] = lm.x
            arr[i, 1] = lm.y
            arr[i, 2] = lm.z
        return arr

    def extract_features(self, landmarks):
        """
        Enhanced feature extraction with geometry and texture
        """
        pts = self._landmark_to_np(landmarks)  # shape (21,3)
        wrist = pts[0, :2]

        # Key indices
        tips = [4, 8, 12, 16, 20]  # Fingertips
        bases = [2, 5, 9, 13, 17]   # Base points

        # Compute palm size
        mcp_middle = pts[9, :2]
        palm_size = np.linalg.norm(mcp_middle - wrist) + 1e-6

        # 1. Normalized fingertip positions
        pos_feats = []
        for idx in tips:
            rel = (pts[idx, :2] - wrist) / palm_size
            pos_feats.extend([rel[0], rel[1]])

        # 2. Inter-fingertip distances
        dist_feats = []
        for i in range(len(tips)):
            for j in range(i+1, len(tips)):
                d = np.linalg.norm(pts[tips[i], :2] - pts[tips[j], :2]) / palm_size
                dist_feats.append(d)

        # 3. Angles between fingers
        angle_feats = []
        for idx in tips:
            v = pts[idx, :2] - wrist
            ang = degrees(atan2(v[1], v[0])) / 180.0
            angle_feats.append(ang)

        # 4. Palm aspect ratio
        index_base = pts[5, :2]
        pinky_base = pts[17, :2]
        middle_tip = pts[12, :2]
        palm_width = np.linalg.norm(index_base - pinky_base)
        palm_height = np.abs(middle_tip[1] - wrist[1]) + 1e-6
        ratio = palm_width / palm_height

        feats = np.array(pos_feats + dist_feats + angle_feats + [ratio], dtype=np.float32)
        return feats

    def scan_palm_for_user(self, user_id, num_scans=6):
        """Capture palm scans and store in database"""
        if not self.db.add_user(user_id):
            self.speak(f"User {user_id} already exists")
            return 0

        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            self.speak("Cannot open camera")
            return 0

        self.speak(f"Starting capture for {user_id}. Please show your palm.")
        saved = 0

        while saved < num_scans and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb)

            if results.multi_hand_landmarks:
                self.mp_drawing.draw_landmarks(frame, results.multi_hand_landmarks[0], 
                                             self.mp_hands.HAND_CONNECTIONS)
                cv2.putText(frame, f"Press 'c' to capture ({saved}/{num_scans})",
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            else:
                cv2.putText(frame, "No hand detected",
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

            cv2.imshow(f"Registering: {user_id}", frame)
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('c') and results.multi_hand_landmarks:
                try:
                    feats = self.extract_features(results.multi_hand_landmarks[0])
                    scan_id = self.db.add_scan(user_id, frame, feats)
                    if scan_id:
                        saved += 1
                        self.speak(f"Captured {saved} for {user_id}")
                        cv2.imshow("Capture Saved", frame)
                        cv2.waitKey(300)
                        cv2.destroyWindow("Capture Saved")
                except Exception as e:
                    print("Error:", e)
            elif key == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()
        self.speak(f"Saved {saved} scans for {user_id}")
        return saved

    def train_model(self):
        """Train model with grid search and cross-validation"""
        scans = self.db.get_all_features()
        if len(scans) < 2:
            self.speak("Need at least two users to train")
            return False

        # Prepare data
        features = []
        labels = []
        for user_id, feat_bytes in scans:
            features.append(pickle.loads(feat_bytes))
            labels.append(user_id)

        X = np.array(features)
        y = np.array(labels)

        # Model pipeline
        pipeline = make_pipeline(
            StandardScaler(),
            RandomForestClassifier(n_estimators=100, max_depth=10)
        )

        # Grid search
        try:
            grid = GridSearchCV(
                estimator=pipeline,
                param_grid={
                    'randomforestclassifier__n_estimators': [50, 100],
                    'randomforestclassifier__max_depth': [5, 10]
                },
                cv=3,
                scoring='accuracy',
                n_jobs=-1,
                verbose=1
            )
            grid.fit(X, y)
            self.model = grid.best_estimator_
            
            # Evaluate
            scores = cross_val_score(self.model, X, y, cv=3)
            mean_acc = float(scores.mean())
            
            # Save model
            self.db.save_model(self.model, mean_acc)
            
            self.speak(f"Model trained with accuracy {mean_acc:.1%}")
            return True
        except Exception as e:
            print("Training failed:", e)
            self.speak("Training failed")
            return False

    def recognize_hand(self):
        """Real-time palm recognition"""
        if not self.model:
            self.speak("Model not trained")
            return

        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            self.speak("Cannot open camera")
            return

        self.speak("Starting recognition. Press q to quit.")
        recent_predictions = []

        while self.recognize_running and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb)

            if results.multi_hand_landmarks:
                lm = results.multi_hand_landmarks[0]
                self.mp_drawing.draw_landmarks(frame, lm, self.mp_hands.HAND_CONNECTIONS)

                try:
                    feats = self.extract_features(lm)
                    probs = self.model.predict_proba([feats])[0]
                    pred = self.model.classes_[np.argmax(probs)]
                    conf = np.max(probs)
                    
                    # Stabilize with recent predictions
                    recent_predictions.append((pred, conf))
                    if len(recent_predictions) > 5:
                        recent_predictions.pop(0)
                    
                    # Get consensus
                    votes = defaultdict(float)
                    for p, c in recent_predictions:
                        votes[p] += c
                    best = max(votes.items(), key=lambda x: x[1])
                    label, score = best
                    score /= len(recent_predictions)
                    
                    cv2.putText(frame, f"{label} ({score:.0%})", 
                               (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    
                    if score > 0.7:
                        self.speak(f"Recognized {label}")
                except Exception as e:
                    print("Recognition error:", e)

            cv2.imshow("Palm Recognition", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()
        self.speak("Recognition stopped")

def main():
    system = PalmBiometricSystem()
    
    while True:
        print("\nPalm Biometric System Menu:")
        print("1. Register New User")
        print("2. Train Model")
        print("3. Start Recognition")
        print("4. View Users")
        print("5. Exit")
        
        choice = input("Select option: ")
        
        if choice == "1":
            user_id = input("Enter user ID: ")
            system.scan_palm_for_user(user_id)
        elif choice == "2":
            system.train_model()
        elif choice == "3":
            system.recognize_running = True
            threading.Thread(target=system.recognize_hand, daemon=True).start()
        elif choice == "4":
            users = system.db.get_user_list()
            print("\nRegistered Users:")
            for user_id, name in users:
                print(f"- {user_id}: {name or 'No name'}")
        elif choice == "5":
            system.recognize_running = False
            system.db.close()
            break
        else:
            print("Invalid choice")

if __name__ == "__main__":
    # Check for required packages
    try:
        main()
    except Exception as e:
        print("Error:", e)
        print("Required packages: mediapipe, opencv-python, scikit-learn, pyttsx3, numpy, pillow")
